---
# ============================================================================
# SYNTHESIS V2.4 — LSTM FIX: Residual + Normalization + Scheduled Sampling
# ============================================================================
#
# BASE: synthesis_v2_4 (best MVAR run, R²=0.730)
#
# LSTM FIXES (professor-reviewed):
#   1. normalize_input: true — z-score per mode, train-set stats only, std≥1e-8
#   2. residual: true        — predict Δy in normalised space
#   3. use_layer_norm: true  — toggleable LayerNorm on LSTM hidden state
#   4. scheduled_sampling     — 2-phase (cosine + linear) ramp, multi-step rollout in window
#   5. multistep_loss: true  — supervised k-step rollout loss (α=0.3, k=5)
#   6. hidden_units: 24      — right-sized (d=10 → 2.4× latent dim)
#
# ============================================================================

experiment_name: "synthesis_v2_4_lstm_fix"

# ============================================================================
# SIMULATION — Same physics as V2.4
# ============================================================================
sim:
  N: 100
  T: 6.0
  dt: 0.04
  Lx: 15.0
  Ly: 15.0
  bc: "periodic"

model:
  type: "discrete"
  speed: 1.5
  speed_mode: "constant_with_forces"

params:
  R: 2.5

noise:
  kind: "gaussian"
  eta: 0.2
  match_variance: true

forces:
  enabled: true
  type: "morse"
  params:
    Ca: 0.8
    Cr: 0.3
    la: 1.5
    lr: 0.5
    mu_t: 0.3
    rcut_factor: 5.0

alignment:
  enabled: true

# ============================================================================
# DENSITY
# ============================================================================
density:
  nx: 48
  ny: 48
  bandwidth: 4.0

outputs:
  density_resolution: 48
  density_bandwidth: 4.0

# ============================================================================
# TRAINING ICs — Same 261 runs
# ============================================================================
train_ic:
  type: "mixed_comprehensive"

  gaussian:
    enabled: true
    n_runs: 180
    positions_x: [3.0, 6.0, 9.0, 12.0]
    positions_y: [3.0, 6.0, 9.0, 12.0]
    variances: [0.8, 1.5, 2.5]
    n_samples_per_config: 3

  uniform:
    enabled: true
    n_runs: 75
    n_samples: 75

  two_clusters:
    enabled: true
    n_runs: 45
    separations: [3.0, 5.0, 7.0]
    sigmas: [1.0, 2.0]
    n_samples_per_config: 7

  ring:
    enabled: false

# ============================================================================
# TEST ICs — Same 26 runs
# ============================================================================
test_ic:
  type: "mixed_test_comprehensive"

  gaussian:
    enabled: true
    n_runs: 15
    test_positions_x: [4.5, 7.5, 10.5]
    test_positions_y: [4.5, 7.5, 10.5]
    test_variances: [1.2]
    n_samples_per_config: 1
    extrapolation_positions: [[2.0, 2.0], [13.0, 2.0], [2.0, 13.0], [13.0, 13.0], [7.5, 1.5], [1.5, 7.5]]
    extrapolation_variance: [1.2]

  uniform:
    enabled: true
    n_runs: 8

  two_clusters:
    enabled: true
    n_runs: 7
    test_separations: [4.0, 6.0]
    test_sigmas: [1.5]
    n_samples_per_config: 3
    extrapolation_separations: [2.0]
    extrapolation_sigma: [1.5]

  ring:
    enabled: false

# ============================================================================
# ROM
# ============================================================================
rom:
  subsample: 3
  fixed_modes: 10

  models:
    mvar:
      enabled: true
      lag: 3
      ridge_alpha: 10.0

    lstm:
      enabled: true
      lag: 3
      hidden_units: 24        # RIGHT-SIZED: 2.4× latent dim → ~3.8k params
      num_layers: 1           # Single layer (was 2) — less overfitting
      max_epochs: 3000
      patience: 150           # More patience for scheduled sampling ramp
      batch_size: 128
      learning_rate: 1.0e-3
      weight_decay: 1.0e-4
      gradient_clip: 1.0
      dropout: 0.0            # No dropout (single layer, small model)

      # ── NEW: LSTM fixes ──
      residual: true           # Predict Δy = y(t+1) - y(t), not raw y
      normalize_input: true    # Z-score POD coefficients per mode
      use_layer_norm: true     # LayerNorm on hidden state before FC head

      # Scheduled sampling: 2-phase ramp to combat exposure bias
      scheduled_sampling: true
      ss_warmup: 20            # No SS before epoch 20
      ss_phase1_end: 200       # Phase 1 (cosine): 0 → 30% over epochs 20-200
      ss_phase1_ratio: 0.3
      ss_phase2_end: 400       # Phase 2 (linear): 30% → 50% over epochs 200-400
      ss_max_ratio: 0.5

      # Multi-step rollout loss: Loss = (1-α)*L_1step + α*L_rollout
      multistep_loss: true
      multistep_k: 5           # Roll forward 5 steps for rollout loss
      multistep_alpha: 0.3     # Weight of rollout loss term

# ============================================================================
# EVALUATION — WITH clamping (like V1)
# ============================================================================
eval:
  metrics: ["r2", "rmse"]
  save_forecasts: true
  save_time_resolved: true
  forecast_start: 0.36
  clamp_negative: true

---
# ============================================================================
# CF10 — K-STEP MVAR VARIANT of CF8 (√ρ + Simplex, d=19, p=5, H37, k=4)
# ============================================================================
#
# IDENTICAL to CF8-champion, but uses k-step MVAR training (k=4).
# Purpose: test if iterative k-step refinement improves R² over standard MVAR.
#
# CF8 achieved R² = +0.515 (lifted) with standard 1-step MVAR(p=5, α=0.01).
# k-step training optimizes the MVAR coefficients over 4-step rollouts,
# penalizing compounding error rather than just 1-step prediction.
#
# ============================================================================

experiment_name: "CF10_longPrefix_sqrtSimplex_kstep4_H37"

# ============================================================================
# SIMULATION — V1 Regime (identical to CF8)
# ============================================================================
sim:
  N: 100
  T: 77.0
  dt: 0.04
  Lx: 15.0
  Ly: 15.0
  bc: "periodic"

model:
  type: "discrete"
  speed: 1.5
  speed_mode: "constant_with_forces"

params:
  R: 2.5

noise:
  kind: "gaussian"
  eta: 0.2
  match_variance: true

forces:
  enabled: true
  type: "morse"
  params:
    Ca: 0.8
    Cr: 0.3
    la: 1.5
    lr: 0.5
    mu_t: 0.3
    rcut_factor: 5.0

alignment:
  enabled: true

# ============================================================================
# DENSITY — 48×48 grid (identical to CF8)
# ============================================================================
density:
  nx: 48
  ny: 48
  bandwidth: 4.0

outputs:
  density_resolution: 48
  density_bandwidth: 4.0

# ============================================================================
# TRAINING ICs — 200 ICs (identical to CF8)
# ============================================================================
train_ic:
  type: "mixed_comprehensive"
  gaussian:
    enabled: true
    n_runs: 120
    positions_x: [3.0, 6.0, 9.0, 12.0]
    positions_y: [3.0, 6.0, 9.0, 12.0]
    variances: [0.8, 1.5, 2.5]
    n_samples_per_config: 2
  uniform:
    enabled: true
    n_runs: 50
    n_samples: 50
  two_clusters:
    enabled: true
    n_runs: 30
    separations: [3.0, 5.0, 7.0]
    sigmas: [1.0, 2.0]
    n_samples_per_config: 5
  ring:
    enabled: false

# ============================================================================
# TEST ICs — 30 held-out ICs (identical to CF8)
# ============================================================================
test_ic:
  type: "mixed_test_comprehensive"
  gaussian:
    enabled: true
    n_runs: 15
    test_positions_x: [4.5, 7.5, 10.5]
    test_positions_y: [4.5, 7.5, 10.5]
    test_variances: [1.2]
    n_samples_per_config: 1
    extrapolation_positions:
      - [2.0, 2.0]
      - [13.0, 2.0]
      - [2.0, 13.0]
      - [13.0, 13.0]
      - [7.5, 1.5]
      - [1.5, 7.5]
    extrapolation_variance: [1.2]
  uniform:
    enabled: true
    n_runs: 8
  two_clusters:
    enabled: true
    n_runs: 7
    test_separations: [4.0, 6.0]
    test_sigmas: [1.5]
    n_samples_per_config: 3
    extrapolation_separations: [2.0]
    extrapolation_sigma: [1.5]
  ring:
    enabled: false

# ============================================================================
# ROM — CF8 + k-step MVAR (k=4)
# ============================================================================
rom:
  subsample: 3
  fixed_modes: 19
  density_transform: "sqrt"
  density_transform_eps: 1.0e-10

  models:
    mvar:
      enabled: true
      lag: 5
      ridge_alpha: 0.01
      kstep_k: 4            # ← NEW: 4-step rollout optimization
    lstm:
      enabled: false

# ============================================================================
# EVALUATION — Same as CF8
# ============================================================================
eval:
  metrics: ["r2", "rmse"]
  save_forecasts: true
  save_time_resolved: true
  forecast_start: 72.0
  clamp_negative: true
  mass_postprocess: simplex

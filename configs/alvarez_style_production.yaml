# ============================================================================
# ALVAREZ-STYLE ROM CONFIG - PRODUCTION VERSION
# ============================================================================
# Well-conditioned MVAR design following Alvarez et al. principles
#
# Key design principles:
#   - Longer training horizon: T = 8.0s (more windows per trajectory)
#   - Micro dt = 0.1s (unchanged)
#   - KDE bandwidth: 3.0 grid cells (more smoothing, lower effective rank)
#   - POD: small latent space d = 20 (fixed_modes)
#   - MVAR: short lag w = 5 (good memory vs. parameter count balance)
#   - Ridge: alpha = 1e-4 (strong regularization)
#   - Eigenvalue scaling: very mild, threshold = 0.999
#   - Test horizon: 10s (extrapolation beyond training)
#
# Identifiability:
#   K = T/dt = 8.0/0.1 = 80 steps per run
#   Windows per run ≈ K - w = 75
#   Total windows: 400 runs × 75 = 30,000
#   Parameters: d²×w = 20²×5 = 2,000
#   Ratio ρ = 30,000/2,000 = 15 ✓ (well-conditioned)
# ============================================================================

# ---------------------------------------------------------------------------
# MICRO MODEL
# ---------------------------------------------------------------------------
sim:
  N: 40
  Lx: 15.0
  Ly: 15.0
  bc: "periodic"
  T: 8.0                    # Training horizon: 8 seconds
  dt: 0.1
  v0: 1.0
  R: 2.0                    # Vicsek interaction radius
  eta: 0.3                  # Noise level

# ---------------------------------------------------------------------------
# DENSITY COMPUTATION (higher smoothing for stability)
# ---------------------------------------------------------------------------
density:
  nx: 64
  ny: 64
  bandwidth: 3.0            # 3 grid cells → more smoothing, lower effective rank

# ---------------------------------------------------------------------------
# TRAINING ICs (rich mix, 400 runs total)
# ---------------------------------------------------------------------------
train_ic:
  gaussian:
    enabled: true
    n_runs: 100  # ignored, uses combinations below
    positions_x: [3.75, 7.5, 11.25]
    positions_y: [3.75, 7.5, 11.25]
    variances: [0.25, 1.0, 4.0, 9.0]  # std: 0.5, 1.0, 2.0, 3.0
    n_samples_per_config: 3  # 3x3x4x3 = 108 runs
  
  uniform:
    enabled: true
    n_runs: 100
  
  ring:
    enabled: true
    n_runs: 100  # ignored, uses combinations below
    radii: [2.0, 3.0, 4.0, 5.0]
    widths: [0.3, 0.3, 0.6, 0.6]
    n_samples_per_config: 25  # 4x25 = 100 runs (samples from 4 ring configs)
  
  two_clusters:
    enabled: true
    n_runs: 100  # ignored, uses combinations below
    separations: [3.0, 4.5, 6.0, 7.5]
    sigmas: [0.8, 0.8, 1.5, 1.5]
    n_samples_per_config: 25  # 4x25 = 100 runs

# ---------------------------------------------------------------------------
# TEST ICs (10s trajectories, out-of-training configurations)
# ---------------------------------------------------------------------------
test_ic:
  gaussian:
    enabled: true
    n_runs: 10
    test_positions_x: [5.5, 9.0, 2.0]
    test_positions_y: [5.5, 9.0, 2.0]
    test_variances: [2.25]  # std: 1.5
  
  uniform:
    enabled: true
    n_runs: 10
  
  ring:
    enabled: true
    n_runs: 10
    test_radii: [2.5, 3.5, 4.5]
    test_widths: [0.45, 0.45, 0.45]
    n_samples_per_config: 1
  
  two_clusters:
    enabled: true
    n_runs: 10
    test_separations: [3.75, 5.25, 6.75]
    test_sigmas: [1.1, 1.1, 1.1]

test_sim:
  T: 10.0                   # Test horizon: 10 seconds (extrapolation)

# ---------------------------------------------------------------------------
# ROM: ALVAREZ-STYLE PARAMETERS
# ---------------------------------------------------------------------------
rom:
  fixed_modes: 20           # FIXED: d = 20 modes (Alvarez principle - takes priority over energy_threshold)

mvar:
  order: 5                  # Lag w = 5 (good memory without too many params)
  ridge_alpha: 1.0e-4       # Strong ridge regularization (key for stability)
  enforce_stability: true
  eigenvalue_threshold: 0.999  # Mild eigenvalue scaling (safety net)
  train_fraction: 0.8       # Use first 80% of each trajectory for training

# ---------------------------------------------------------------------------
# EVALUATION (measure extrapolation from end of training)
# ---------------------------------------------------------------------------
eval:
  forecast_dt: 1
  save_time_resolved: true
  metrics:
    - "mse"
    - "mae"
    - "r2"
    - "mass_conservation"

# ---------------------------------------------------------------------------
# QUALITATIVE EFFECTS
# ---------------------------------------------------------------------------
# - Larger bandwidth (3.0) smooths high-frequency noise → steeper POD spectrum
# - Fixed d=20 models only large-scale density structure (intentional)
# - Short lag w=5 balances temporal memory with parameter efficiency
# - Strong ridge alpha=1e-4 regularizes fit, reduces overfitting
# - Mild eigenvalue threshold is safety net, not primary stabilization
# - Result: Well-conditioned MVAR with excellent identifiability ratio

# ROM/MVAR Evaluation Pipeline Guide

Complete guide to training, evaluating, and visualizing Reduced-Order Models (ROM) based on global POD + MVAR for collective motion dynamics.

## Overview

This pipeline implements the evaluation strategy from Alvarez et al.:
1. **Training**: Generate augmented ensemble with varied ICs → compute global POD basis → fit MVAR on latent data
2. **Evaluation**: Test generalization on unseen ICs → compute comprehensive metrics
3. **Visualization**: Post-hoc generation of videos and plots from saved data

**Key feature**: Clean separation between computation (Oscar-friendly) and visualization (local).

## Directory Structure

```
rom_mvar/
└── <experiment_name>/
    ├── model/
    │   ├── pod_basis.npz           # POD modes, mean mode, grid info
    │   ├── mvar_params.npz         # A_0, A_j matrices, order, latent_dim
    │   └── train_summary.json      # Training metadata
    ├── test_ics/
    │   ├── ic_0000/
    │   │   ├── true_density.npz
    │   │   ├── pred_density.npz
    │   │   ├── metrics_timeseries.csv
    │   │   ├── metrics_summary.json
    │   │   └── videos/             # Generated by visualize script
    │   │       ├── density_comparison.gif
    │   │       └── error_dashboard.png
    │   └── ic_0001/
    │       └── ...
    └── aggregate_metrics/
        ├── all_test_metrics.csv
        └── aggregate_summary.json
```

## Quick Start

### 1. Training (Oscar)

```bash
# Submit training job
sbatch scripts/slurm/job_mvar_train.sh configs/rom_mvar_example.yaml

# Or use complete pipeline script
bash scripts/slurm/submit_mvar_pipeline.sh configs/rom_mvar_example.yaml
```

### 2. Evaluation (Oscar)

```bash
# Evaluation runs automatically if using pipeline script
# Or submit manually after training
sbatch scripts/slurm/job_mvar_eval.sh gentle_clustering configs/rom_mvar_example.yaml
```

### 3. Visualization (Local)

```bash
# Sync results from Oscar
rsync -avz oscar:/users/emaciaso/src/wsindy-manifold/rom_mvar/gentle_clustering/ \\
    rom_mvar/gentle_clustering/

# Generate videos and plots
python scripts/rom_mvar_visualize.py --experiment gentle_clustering
```

## Configuration

### Example Config (`configs/rom_mvar_example.yaml`)

```yaml
# Base simulation parameters
model: social_force
sim:
  N: 100
  Lx: 20.0
  Ly: 20.0
  T: 50.0
  dt: 0.01
  save_every: 5

# ROM training settings
rom:
  experiment_name: gentle_clustering
  rom_root: rom_mvar
  
  # Training ensemble
  num_train_ics: 10              # Number of training simulations
  train_seeds: null              # null = auto-generate
  
  # POD settings
  energy_threshold: 0.995        # Retain 99.5% energy
  latent_dim: null               # null = use energy threshold
  
  # MVAR settings
  mvar_order: 4                  # Number of lags
  ridge: 1.0e-6                  # Ridge regularization
  train_frac: 1.0                # Use all time steps
  
  # Evaluation settings
  eval:
    num_test_ics: 2              # Unseen test ICs
    test_seeds: null             # null = [1000, 1001, ...]
    forecast_horizon: null       # null = full simulation
    error_tolerance: 0.1         # For tolerance horizon τ
    error_metric: rmse           # Metric for τ
    generate_videos: false       # False for Oscar
    generate_plots: false        # False for Oscar
```

### CLI Overrides

```bash
# Override training parameters
python scripts/rom_mvar_train.py \\
    --config configs/rom_mvar_example.yaml \\
    rom.num_train_ics=20 \\
    rom.mvar_order=6

# Override evaluation parameters
python scripts/rom_mvar_eval.py \\
    --experiment my_experiment \\
    --config configs/rom_mvar_example.yaml \\
    rom.eval.num_test_ics=5 \\
    rom.eval.error_tolerance=0.05
```

## Detailed Workflow

### Step 1: Training Pipeline

**Script**: `scripts/rom_mvar_train.py`

**What it does**:
1. Generates `M_train` simulations with varied initial conditions
2. Stacks all density snapshots across time and ICs
3. Computes global POD basis (one basis for all data)
4. Projects all training runs to latent space
5. Fits MVAR model: `z_t = A_0 + Σ A_j z_{t-j}`
6. Saves model artifacts to `model/`

**Outputs**:
- `pod_basis.npz`: POD modes, mean mode, singular values
- `mvar_params.npz`: MVAR coefficients A_0, A_1, ..., A_p
- `train_summary.json`: Metadata (latent dim, compression ratio, etc.)

**Key Parameters**:
- `num_train_ics`: Number of training simulations (default: 10)
- `energy_threshold`: POD energy threshold (default: 0.995)
- `mvar_order`: MVAR lags (default: 4)
- `ridge`: Ridge regularization (default: 1e-6)

### Step 2: Evaluation Pipeline

**Script**: `scripts/rom_mvar_eval.py`

**What it does**:
1. Loads trained POD + MVAR model
2. Generates `K_test` simulations with **unseen** ICs
3. For each test IC:
   - Runs ground truth simulation
   - Projects initial states to latent space
   - Forecasts using MVAR
   - Reconstructs density from latent forecast
   - Computes per-time-step metrics
4. Saves per-IC results and aggregate statistics

**Metrics Computed**:
- **R²**: Coefficient of determination
- **RMSE**: Root mean squared error
- **e2**: Relative L² error
- **einf**: Relative L∞ error
- **mass_error**: Absolute mass conservation error
- **τ (tolerance horizon)**: Max time within tolerance

**Outputs (per IC)**:
- `true_density.npz`: Ground truth density evolution
- `pred_density.npz`: MVAR-predicted density evolution
- `metrics_timeseries.csv`: Per-time-step metrics
- `metrics_summary.json`: Aggregated statistics

**Outputs (aggregate)**:
- `all_test_metrics.csv`: One row per test IC
- `aggregate_summary.json`: Mean/std/min/max across ICs

**Oscar-Friendly Defaults**:
- `generate_videos: false` (no ffmpeg issues)
- `generate_plots: false` (no heavy IO)
- All numeric computation is done and saved

### Step 3: Visualization Pipeline

**Script**: `scripts/rom_mvar_visualize.py`

**What it does**:
- **NO SIMULATION** - purely reads saved NPZ/CSV
- Generates comparison videos (true vs predicted density)
- Creates error dashboard plots with τ marked
- Saves to `videos/` subdirectory

**Usage**:
```bash
# Visualize all ICs
python scripts/rom_mvar_visualize.py --experiment my_experiment

# Visualize specific ICs
python scripts/rom_mvar_visualize.py --experiment my_experiment --ic_ids 0 1 2

# Skip videos (only plots)
python scripts/rom_mvar_visualize.py --experiment my_experiment --no_videos
```

**Outputs**:
- `density_comparison.gif`: Side-by-side true vs predicted
- `error_dashboard.png`: Comprehensive error plots with τ

## Tolerance Horizon (τ)

The **tolerance horizon** τ measures how long the ROM stays within a specified error tolerance:

```
τ = max{t : error(s) ≤ tol for all s ≤ t}
```

**Configuration**:
- `error_tolerance`: Tolerance threshold (default: 0.1)
- `error_metric`: Which metric to use for τ (default: 'rmse')
  - Options: 'rmse', 'r2', 'e2', 'einf', 'mass_error'

**Interpretation**:
- τ = 50: Model stays accurate for 50 time steps
- τ = 0: Model exceeds tolerance immediately
- τ = T: Model stays within tolerance for entire simulation

Visualizations mark τ with a vertical green line on error plots.

## Oscar Workflow

### Training + Evaluation

```bash
# On Oscar
cd ~/src/wsindy-manifold

# Submit complete pipeline (train → eval with dependency)
bash scripts/slurm/submit_mvar_pipeline.sh configs/rom_mvar_example.yaml

# Monitor jobs
squeue -u $USER
watch -n 5 'squeue -u $USER'

# Check logs
tail -f logs/rom_train_*.log
tail -f logs/rom_eval_*.log
```

### Sync and Visualize Locally

```bash
# On laptop
cd ~/Desktop/wsindy-manifold

# Sync results from Oscar
oscar-sync from rom_mvar/gentle_clustering

# Or manual rsync
rsync -avz oscar:/users/emaciaso/src/wsindy-manifold/rom_mvar/gentle_clustering/ \\
    rom_mvar/gentle_clustering/

# Generate visualizations
python scripts/rom_mvar_visualize.py --experiment gentle_clustering

# View results
open rom_mvar/gentle_clustering/test_ics/ic_0000/videos/error_dashboard.png
open rom_mvar/gentle_clustering/test_ics/ic_0000/videos/density_comparison.gif
```

## Advanced Usage

### Custom Training Seeds

```yaml
rom:
  num_train_ics: 5
  train_seeds: [42, 123, 456, 789, 101112]  # Explicit seeds
```

### Fixed Latent Dimension

```yaml
rom:
  energy_threshold: 0.995  # Ignored when latent_dim is set
  latent_dim: 20           # Use exactly 20 POD modes
```

### Temporal Train/Test Split

```yaml
rom:
  train_frac: 0.8          # Use first 80% of time steps for training
                           # (Currently fits MVAR on all data)
```

### Custom Forecast Horizon

```yaml
rom:
  eval:
    forecast_horizon: 100  # Forecast only 100 steps instead of full simulation
```

## Metrics Reference

### Per-Time-Step Metrics

Computed for each time step t in `metrics_timeseries.csv`:

| Metric | Formula | Interpretation |
|--------|---------|----------------|
| `r2` | `1 - SS_res / SS_tot` | Coefficient of determination (1 = perfect) |
| `rmse` | `sqrt(mean((true - pred)²))` | Root mean squared error (lower = better) |
| `e2` | `||true - pred||_2 / ||true||_2` | Relative L² error (lower = better) |
| `einf` | `||true - pred||_∞ / ||true||_∞` | Relative L∞ error (lower = better) |
| `mass_error` | `|M_true - M_pred|` | Absolute mass difference |

### Summary Metrics

Aggregated in `metrics_summary.json`:

- `r2_mean`, `r2_median`, `r2_min`: R² statistics
- `rmse_mean`, `rmse_median`, `rmse_max`: RMSE statistics
- `mass_error_mean`, `mass_error_max`: Mass error statistics
- `tolerance_horizon`: τ for specified metric and tolerance

### Aggregate Metrics

Across all test ICs in `aggregate_summary.json`:

- Mean ± std for each summary metric
- Min/max across ICs
- Overall generalization performance

## Troubleshooting

### Training fails with memory error

Reduce grid resolution or number of training ICs:
```yaml
outputs:
  grid_density:
    nx: 32  # Reduce from 64
    ny: 32

rom:
  num_train_ics: 5  # Reduce from 10
```

### Evaluation runs out of time

Reduce simulation length or test ICs:
```yaml
sim:
  T: 25.0  # Reduce from 50.0

rom:
  eval:
    num_test_ics: 1  # Reduce from 2
```

### Visualization fails

Check that evaluation completed successfully:
```bash
ls rom_mvar/my_experiment/test_ics/ic_0000/
# Should see: true_density.npz, pred_density.npz, metrics_*.{csv,json}
```

### Poor generalization (low τ)

Try:
1. Increase POD modes: `latent_dim: 30`
2. Increase MVAR order: `mvar_order: 6`
3. More training data: `num_train_ics: 20`
4. Longer simulations: `T: 100.0`

## Citation

If you use this pipeline, please cite:

Alvarez et al. (2023). "Forecasting of density time series with deep learning and the Koopman operator". https://arxiv.org/abs/2306.11375

## See Also

- [Main README](../README.md): General package documentation
- [MVAR_GUIDE.md](MVAR_GUIDE.md): Original MVAR pipeline (deprecated)
- [rom/README.md](../rom/README.md): Legacy ROM evaluation (superseded by this)

---

**Last updated**: November 2025  
**Author**: Maria
